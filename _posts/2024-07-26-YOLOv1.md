---
title: 'YOLOv1; You Only Look Once: Unified, Real-Time Object Detection'
tags:
- paper_review
- 9S_July2024
categories:
- AI
---

최근에 한 프로젝트를 진행하다가 object detection 이 필요하게 되었다. object detection 을 하는 AI model 을 찾아보고 있었는데 YOLO 가 벌써 v10 까지 나온 것을 보게 되었다. YOLO 에 관해 간단히 공부해본 적은 있으나 논문을 읽어본 적은 없어서 가장 처음으로 YOLO를 제안한 논문을 읽어보게 되었다. 

예전에 자율주행차량 등이 활발하게 연구되기 시작할 무렵에는 object detection 이 AI 학계에서 가장 큰 이슈이자 트렌드였다. 정확하면서도 빠른 object detection model 을 만들어내기 위해 많은 연구가 이루어졌고 YOLO 시리즈는 real-time object detection 에서 대부분 SOTA 를 가져갔고, 현재까지도 매우 유명하고 대표적인 object detection 모델이다. 본 논문을 시작으로 YOLOv2, v3, …, 최근에 v10 까지 나왔으며 각 버전은 이전의 YOLO를 기반으로 다른 architecture 로 변형시키거나 상당히 새로운 architecture 를 가지고 온 경우도 많았다. 특히나 v9 부터는 필자가 보기엔 원래의 YOLO와 완전히 달라진 것 같다. 그만큼 real-time object detection 이 많이 발전했고 YOLO series 는 그 계보라 할 수 있다.

2017년에 Attention 이 처음 등장하며 AI 의 패러다임을 크게 바꾸었고 Transformer 등이 등장하였다. 이후 YOLO 에도 Transformer 가 적용되었으며 원래 대화형 모델을 위해 만들어진 Transformer 를 image detection 에 적용하기 시작했으며 꽤 성능이 좋았다. 대표적으로 ViT 등이 있다. 

이후 Generative AI 가 등장하며 multi-modal AI 의 시대가 열렸다. 현재 AI 학계의 가장 큰 트렌드는 Generative AI 이며 사람처럼 매우 다양한 task 를 종합적으로 수행할 수 있는 AI model 을 연구하는 방향으로 흘러가고 있다. 생성형 AI 에서 image detection 도 같이 하는 모델도 있으며 현재는 object detection 에 관한 연구는 좀 시들한 상태다.

제아무리 생성형 AI 에서 image detection 을 같이 하기도 한다지만, 정확한 object detection 은 아직 못한다. 그래서 아직도 object detection model 은 연구가 되고 있고 YOLO series 도 계속 연구 및 발전하고 있는 듯 하다. YOLOv8 까지는 논문이 있고 YOLOv9, v10 은 코드만 공개되어 있고 논문이 아직 없다. 언제 나올지는 모르겠는데 한 번 나왔으면 좋겠다.

그럼 object detection 의 대표 주자 YOLO의 첫 버전을 살펴보자.

## 1. Introduction

YOLO 이전의 object detection에 관한 연구들은 classifier가 detection을 하는 방식이었다. 당시에는 나온지 얼마 안된 R-CNN 같은 경우 region proposal을 통해서 잠재적인 bounding box를 얻어내고 그 potential box들에 대해 classifier를 각각 적용시켰다. classification 이후에는 후처리를 해서 bounding box의 중복을 없애고 다시 전반적인 정보를 바탕으로 rescore 하는 등의 처리를 했다. 딱 봐도 이 과정이 복잡해보이지 않는가? 이렇게 복잡한 “pipeline”은 각 요소의 학습이 별개로 이루어졌기 때문에 속도가 느리고 최적화하기 어려웠다.

YOLO는 object detection을 single regression problem으로 만들었다. Full image pixel을 입력으로 받아서 하나의 model로 bounding box 좌표와 class probability를 모두 도출한 것이 YOLO 의 핵심이다.

YOLO가 unified model 이어서 생기는 장점은 아래와 같다.

- 매우 빠르다. 복잡한 pipeline이 필요하지 않다.
- 예측을 할 때 (prediction) image 전체의 정보를 바탕으로 예측을 한다. image 전체를 바탕으로 각 class의 contextual 정보도 이용한다는 것이다.
- 일반화된 (generalized) 학습을 한다. training 한 것과 다른 형태 혹은 예상하지 못한 input이 들어와도 일반화가 잘 되어 있기 때문에 잘 대응할 수 있음. 예를 들어, 자연 이미지 (실제 사진)에서 학습을 하고 그림에서 object detection test를 했는데 다른 model보다 월등히 뛰어났다.

YOLO는 SOTA (state-of-the-art) 보다 “정확도” 에서는 뒤처진다. 특히 작은 물체를 잘 인식하지 못하는데 이는 localize (지역화)에서 문제가 발생한 것이다. SOTA 보다 정확도는 조금 뒤처지지만 속도는 월등히 빠르다는 것이 YOLO 의 핵심 포인트다.

## 2. Unified Detection

본 모델은 추론을 할 때 전체 image의 정보와 image에 있는 모든 object 와의 상관관계에 관한 정보를 활용한다. 전체적으로는 아래와 같은 과정으로 detection 이 진행된다.

- input image를 S * S 개의 grid로 나눔. image에 있는 object의 중심이 속해있는 grid가 해당 object를 인식해야 하는 grid가 된다.
- 각 grid cell은 B개의 bounding box와 각 box에 대한 confidence score 를 예측(predict) 한다.
    - confidence score : $Pr(Object)\times IOU^{truth}\_{pred}$
- 각 bounding box는 5개의 prediction 으로 구성된다.
    - x, y : bounding box의 중심 좌표. grid cell의 경계에 대해 상대적인 좌표로 grid cell의 x축 크기, y축 크기로 normalize 해서 0-1 사이의 값으로 나타냄.
    - w, h : bounding box의 width, height. image 전체의 크기로 normalize 해서 나타내어 0-1 사이의 값으로 나타냄.
    - confidence : predicted box와 ground truth box 간의 IOU (intersection over union)
- 각 grid cell은 C 개의 conditional class probability , $Pr(Class_i \mid Object)$ 를 예측한다. 하나의 grid cell 에서는 한 개 set의 conditional class probability 만 예측한다. B개의 bounding box가 grid 에 있어도 grid 에 대해서는 class 개수 만큼의 conditional class probability 만 있다.
- test 시에는 conditional class probability와 bounding box에서 예측한 confidence를 아래와 같이 곱한다.
    - $Pr(class\_i \mid Object)\times Pr(Object)\times IOU^{truth}\_{pred}=Pr(Class\_i)\times IOU^{truth}\_{pred}$
- 이러한 prediction 들을 S * S * (B * 5 + C) 크기의 tensor로 나타낸다.
    - S * S : grid 개수
    - B * 5 + C : grid 의 bounding box 마다 5개의 prediction 요소, 각 grid 마다 C 개의 conditional class probability

### 2.1 Network Design
<img width="885" alt="Untitled" src="https://github.com/user-attachments/assets/0cf4da0a-6e8c-4fb2-91a8-affdd39d8b8d">

본 model은 convolutional neural network 로 구현되었다. 초기의 convolutional layer는 image에서 feature를 추출하고 뒤의 fully connected layer 들은 output에서의 확률과 box 좌표를 예측하는 역할을 한다. 자세한 구조는 위의 그림과 같다.

GoogLetNet을 참조하여 설계하였다. 총 24개의 convolutional layer 뒤에 fully connected layer 2개를 붙인 형태인 것을 볼 수 있다. 

본 논문에서는 inference 속도를 높인 Fast YOLO 도 제안하였다. 앞에서 설명한 architecture에서 24개의 convolutional layer를 9개로 줄인 형태이다. layer마다 filter 개수도 줄였다.

본 논문에서는 B (grid 마다 bounding box 개수) = 2, C (class 개수) = 20, S (grid 나눈 개수, S * S 개의 grid 로 image 를 나눔) = 7로 설정했다. 즉, network의 output은 7 * 7 * 30 크기의 tensor가 된다.

### 2.2 Training

첫 20개의 convolutional layer에 average-pooling layer와 fully connected layer를 붙여서 ImageNet 1000-class competition dataset으로 “pretraining” 을 했다. 이 때 Darknet framework를 사용했다.

pretraining 후에 detection을 하는 model 로 변환했다. Ren et al. 에서 pretrain 된 network에 convolutional layer 와 connected layer를 붙이면 성능이 향상된다고 했으며 이를 참고하여 4개의 convolutioinal layer와 2개의 fully connected layer 붙였다. (이를 통해 앞에서 설명한 architecture 인 24개 convolutional layer + 2개 fully connected layer 가 되는 것을 확인할 수 있음) 

detection 할 때는 좀 더 정밀한 visual 정보가 필요하기 때문에 input resolution을 224x224에서 448x448로 늘렸다.

final layer는 class probability와 bounding box 좌표들을 모두 예측하게 된다. final layer에는 linear activation function 을 사용했고 이외의 모든 layer에는 leaky rectified linear activation function (Leaky ReLU) 인 $\phi(x)=x\ (if\, \, x > 0), \, \, 0.1x\, \, (otherwise)$  를 사용했다.

training 의 목표는 output의 sum-squared error를 최적화하는 것이다. 학습에는 optimization 이 쉬운 sum-squared error 를 사용했다. 하지만, 이 방식은 classification error 와 localization error 를 동등하게 취급하고, object 가 없는 grid cell은 confidence score가 0이 되어 object 가 있는 grid cell의 gradient 영향이 커져서 model이 불안정해질 수 있다. 이는 average precision 을 떨어트릴 수 있다.

이를 보완하기 위해 bounding box 좌표 예측에 대한 loss를 증가시키고, object가 없는 box의 confidence를 예측하는 것에 대한 loss를 감소시켰다. 또한, 큰 box에서의 좌표 편차는 작은 box에서의 좌표 편차보다 영향이 작은 것을 반영하기 위해 box width와 height를 예측할 때 $\sqrt{width}, \sqrt{height}$ 값을 예측하도록 하였다.

마지막으로 하나의 object에 대해 ground truth와 IoU가 가장 큰 predictor 하나를 도출하여 해당 object에 대해 “responsible” 한 predictor로 지정하고 학습을 진행하며 object에 특화되도록 했다.

결과적인 loss function 은 아래와 같다.

![Untitled 1](https://github.com/user-attachments/assets/5435e693-af3e-4041-aaca-967df207b009)

식을 살펴보면 loss function은 object가 포함된 grid cell에 대해서만 classification error에 loss를 부여하고 있고, “responsible” 한 predictor에 대해서만 bounding box 좌표 error에 loss를 부여하는 것을 확인할 수 있다.

learning rate schedule은 첫 epoch에서 learning rate를 10^-3 → 10^-2로 서서히 증가시키고 (통상적으로 학습시킬 때 처음에 learning rate 가 너무 높으면 diverge 해버릴 수 있음), 75 epoch 까지 learning rate를 10^-2 로 유지하다가, 이후 30 epoch는 10^-3, 마지막 30 epoch는 10^-4 로 설정하였다.

overfitting을 방지하기 위해 첫 connected layer 이후에 dropout (일정 확률로 neuron 제거하는 것)을 적용하고 extensive data augmentation (원래 training data를 변형한 것을 training data 에 추가하는 것)도 적용했다.

### 2.3 Inference

YOLO의 가장 큰 특징 중 하나는 classifier-based method 와는 다르게 하나의 network 만 evaluation 하면 되기 때문에 test 할 때 속도가 매우 빠르다는 것이다. grid cell design은 bounding box 예측에 있어서 공간적인 다양성을 부여하는 역할을 한다. 큰 object나 여러 cell에 걸쳐 있는 object는 여러 cell에서 인식될 수 있는데 이는 Non-maximal supression (NMS) 를 적용하여 해결했다.

(참고 : NMS 는 hand-crafted algorithm 이다. 학습되거나 하는 것이 아닌 heuristic 한 특성이 있기 때문에 object detection 에 있어서 안 좋은 영향을 준다고 평가하는 논문도 있었다. DETR, Detection Transformer, 논문이었음)

### 2.4 Limitations of YOLO

본 논문에서 제안한 YOLOv1 에는 많은 한계점이 있다. 이 당시에는 굉장히 획기적인 모델이었겠지만 지금보면 성능에 큰 영향을 끼치는 한계점들이 많다.

각 grid cell이 오직 2개의 bounding box만 예측가능하며 grid cell 마다 한 개 class 만 예측가능하기 때문에 이는 엄청난 공간적 제약이다. 그래서 본 논문에서 제안하는 모델은 무리 지어 나타나는 작은 object는 인식을 잘 못하게 된다.

bounding box를 예측할 때 학습된 data만을 바탕으로 하기 때문에 아예 새로운 object, 새로운 형상의 object에는 일반화가 안된다. (근데 이거는 다른 model 도 마찬가지 아닐까? training 을 시키지도 않은 object 를 어떻게 detection 하겠는가)

loss function이 작은 bounding box에서의 error와 큰 bounding box에서의 error를 가중치가 같도록 취급한다. 큰 bounding box 에서의 작은 error 는 그닥 큰 문제가 아니지만 작은 bounding box 에서 똑같은 작은 error 는 큰 문제가 될 수 있다. 이에 대한 차별성이 필요한데 현재 loss 에서는 차별을 두고 있지 않다. 이 때문에 YOLOv1 모델에서 발생하는 error의 가장 주요한 원인은 부정확한 localization 이다.

## 3. Comparison to Other Detection Systems

다른 model들과 비교하며 동등한 accuracy와 performance를 내면서 real-time performance를 낼 만큼 처리 속도가 빠른 것은 YOLO라고 주장하고 있다. 자세한 설명은 논문을 참조하라.

## 4. Experiments

YOLO에서 발생하는 많은 error를 분석했을 때 YOLO를 Fast R-CNN을 보완하는 형태로 사용하면 Fast R-CNN 에서 문제가 되었던 background false positive error를 감소시켜 성능을 끌어올리는 역할을 할 수 있음을 보여주었다.

이외에도 YOLO model로 test 한 결과를 이 chapter에서 보여주고 있다.

### 4.1 Comparison to Other Real-Time Systems

Fast YOLO는 PASCAL 에서 가장 빠른 object detection method 이다. 실험 결과 YOLO는 real-time performance를 유지하며 63.4%의 mAP (mean average precision) 성능을 보였다. Fast R-CNN은 R-CNN의 classification stage를 빠르게 하지만 selective search (bounding box 제안을 생성하기 위해 사용) 를 사용하기 때문에 여전히 0.5 fps의 느린 처리 속도를 나타내었다. 이후 나온 Faster R-CNN은 selective search를 neural network로 대체하였는데, 그래도 YOLO 보다 훨씬 느리고 정확도는 약간 높거나 낮게 나왔다.

### 4.2 VOC 2007 Error Analysis

VOC 2007 dataset 으로 test 한 결과를 바탕으로 YOLO의 error 요인을 5개 카테고리로 나눠서 분석하고 가장 성능이 좋은 Fast R-CNN과 비교하였고, YOLO는 Fast R-CNN보다 localization error가 매우 많지만 background error는 적다는 것을 알 수 있었다고 한다.

### 4.3 Combining Fast R-CNN and YOLO

Fast R-CNN에서 background error를 없애기 위해 YOLO와 결합하면 performance가 향상되는 것을 확인했다. R-CNN에서 예측한 모든 bounding box에 대해 YOLO에서 예측한 box중 비슷한 box가 있으면 그 box prediction에 weight를 실어주는 방식을 사용했다. 

Fast R-CNN과 YOLO를 결합한 model은 상당한 정확도 향상을 보였다. 하지만, YOLO가 처리 속도가 빨라도 Fast R-CNN의 처리 속도가 느렸기에 두 모델을 결합해도 YOLO의 빠른 처리 속도가 무의미해지는 문제가 있었다.

### 4.4 VOC 2012 Results

이 dataset 에서는 SOTA에 비해 mAP가 좀 낮았다. 작은 물체들을 인식하지 못하는 문제 때문이었다. Fast R-CNN 과 YOLO를 결합한 모델은 mAP performance가 매우 좋았다.

### 4.5 Generalizability: Person Detection in Artwork

실제 상황에서는 model이 학습했던 것과 완전히 다른 test data가 있을 수 있고 모든 경우를 예측하여 학습할 수는 없다. Picasso Dataset과 People-Art Dataset에서 그림에서 사람을 detection 하는 task 에 대해 YOLO와 이전의 detection system 을 비교했다.

YOLO는 object의 크기, 모양 뿐만 아니라 object 간의 관계, object가 주로 어디에서 나타나는지를 modeling 하기에 실제 image와는 다른 그림 image에서도 object의 크기, 모양 등의 특징을 통해 bounding box 예측과 detection이 비교적 잘 이루어지는 것을 확인할 수 있었다.

## 5. Real-Time Detection In The Wild

실제 webcam 영상에 YOLO를 연결하여 real-time 영상 detection을 test해본 결과 좋은 real-time performance를 보여줌. webcam에서 image를 fetch 하고 detection 결과를 display 하는 것까지의 속도가 매우 빨라서 실시간으로 object를 tracking 하는 것처럼 기능했다고 한다.

## 6. Conclusion

YOLO는 object detection을 하는 “unified model” 이며 모델 구조가 복잡하지 않고 전체 image로 직접적으로 training 이 가능하다는 점이 특징이다. classifier-based method 와는 다르게 YOLO는 detection 성능과 직접적으로 연관된 loss function으로 training 되고 전체 model이 단일 model로서 학습된다.

당시 Fast YOLO 는 general-purpose object detection 에서 가장 빠른 모델이었다. YOLO는 정확도를 향상시키는 것에 focus 하기 보다는 SOTA와 비슷한 정확도를 보장하면서 “real-time” object detection에 특화된 모델이다. (근데 최근 나온 YOLOv7, v8, v9 의 경우 정확도 면에서도 큰 개선을 하여 real-time 이라는 특징을 고수하면서도 SOTA 보다 더 높은 정확도를 나타내고 있다)

마지막으로 학습이 이루어진 domain이 아닌 새로운 domain에서도 일반화가 잘 된다는 것이 YOLO의 특징이다.

### Comment

This post is the part of ‘Uploading 5 academic blog posts’ which is July’s resolution project in 9th squad.

본 post 는 9th Squad 의 7월 목표에서 필자의 목표인 ‘학술 블로그 포스트 5개 업로드’ 의 일환임을 알림
